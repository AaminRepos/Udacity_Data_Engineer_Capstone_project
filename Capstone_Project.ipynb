{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Udacity Data Enginering nanodegree capstone poject\n",
    "### U.S city average temperature and Immigration data Data Lake\n",
    "\n",
    "#### Project Summary\n",
    "Generally the scope of this project is to model the data lake allowing users to capture and visualise the changeof ground tempratures throught out the years, now i have chosen to includetemperatures measured even before commercial airtravel was introduced.\n",
    "\n",
    "We will attempt read, write and analyise data for more than 200k+ travelers\n",
    "using spark for our U.S immigration data provided by the US National Tourism\n",
    "and Trade Office, residing on a github repository as well as the World Temperature Data found on kaggle, U.S. City Demographic Data from OpenSoft and finally, U.S Airport Code Table data.\n",
    "\n",
    "links for the data sources all provided in the last cell.\n",
    "\n",
    "Deploying a star schema database desing as the immigration data is the fact table vs\n",
    "the national temprature readings table, the national land air and sea ports table, \n",
    "the us city demographics table as dimension tables, and finally a time table extracted from\n",
    "our immigration data\n",
    "\n",
    "The last table here is essential, for an example if the city x, maitains a yearly population growth rate of 2%, an average of 1000 tourists a year and an average of +0.0005 degrees a year\n",
    "\n",
    "On the random year z, we see an increase of 1.0 degrees on april, the data from our demographics table indicates that on the same year we see an increase of 15% in the population\n",
    "yet we maintain the 1000 tourists a year indicated from out fact table, and in this case we can\n",
    "conclude that immigration was not the cause of the increase in the temprature recorded.\n",
    "\n",
    "\n",
    "Or simply to see if we can notice any significant changes in demographics based on immigration.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# imports and installs\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import (year, month, dayofmonth, hour,\n",
    "weekofyear, date_format, dayofweek)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "\n",
    "while we might need to run a scheduled ELT pipeline in most cases of DataLakes,\n",
    "using airflow to run the extract load and transform processes for this project is so far an option but might get complicated with jupyter and the project's viewer python version among other things to consider.\n",
    "\n",
    "We have a sample to our immigration data and the full data for the dimensions tables loaded below to determine the data wrangling steps we need to execute.\n",
    "\n",
    "#### Cleaning Steps\n",
    "\n",
    "while data analyists prefer well structered and defined data but data scientists prefer raw data or as unchanged as possiple, I will maintain minumum changes to the data set yet allowing for both by definning a proper data type format, the absence of null values and duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "demo_df = pd.read_csv('us-cities-demographics.csv', sep =';')\n",
    "df_ports = pd.read_csv('airport-codes_csv.csv')\n",
    "migration = pd.read_csv('immigration_data_sample.csv')\n",
    "\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temp_df = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>Boise</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>34.9</td>\n",
       "      <td>110099.0</td>\n",
       "      <td>108181.0</td>\n",
       "      <td>218280</td>\n",
       "      <td>16004.0</td>\n",
       "      <td>13409.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>ID</td>\n",
       "      <td>Asian</td>\n",
       "      <td>9806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City  State  Median Age  Male Population  Female Population  \\\n",
       "2556  Boise  Idaho        34.9         110099.0           108181.0   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "2556            218280             16004.0       13409.0   \n",
       "\n",
       "      Average Household Size State Code   Race  Count  \n",
       "2556                    2.61         ID  Asian   9806  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data sample\n",
    "demo_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#dataframe's information\n",
    "demo_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "State                      0\n",
       "Median Age                 0\n",
       "Male Population            3\n",
       "Female Population          3\n",
       "Total Population           0\n",
       "Number of Veterans        13\n",
       "Foreign-born              13\n",
       "Average Household Size    16\n",
       "State Code                 0\n",
       "Race                       0\n",
       "Count                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting any null values\n",
    "demo_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>Riverview</td>\n",
       "      <td>Florida</td>\n",
       "      <td>32.2</td>\n",
       "      <td>44210.0</td>\n",
       "      <td>45536.0</td>\n",
       "      <td>89746</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>12240.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>FL</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>15159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>Gastonia</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>36.9</td>\n",
       "      <td>35527.0</td>\n",
       "      <td>39023.0</td>\n",
       "      <td>74550</td>\n",
       "      <td>3537.0</td>\n",
       "      <td>5715.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>NC</td>\n",
       "      <td>White</td>\n",
       "      <td>46362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           City           State  Median Age  Male Population  \\\n",
       "2500  Riverview         Florida        32.2          44210.0   \n",
       "1614   Gastonia  North Carolina        36.9          35527.0   \n",
       "\n",
       "      Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "2500            45536.0             89746              6943.0       12240.0   \n",
       "1614            39023.0             74550              3537.0        5715.0   \n",
       "\n",
       "      Average Household Size State Code                       Race  Count  \n",
       "2500                    3.22         FL  Black or African-American  15159  \n",
       "1614                    2.67         NC                      White  46362  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data sample\n",
    "demo_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#dataframe's information\n",
    "df_ports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting any null values\n",
    "df_ports.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>3MD2</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Garrett County Memorial Hospital Heliport</td>\n",
       "      <td>2457.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MD</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>3MD2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3MD2</td>\n",
       "      <td>-79.40119934082031, 39.41320037841797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ident      type                                       name  elevation_ft  \\\n",
       "4393  3MD2  heliport  Garrett County Memorial Hospital Heliport        2457.0   \n",
       "\n",
       "     continent iso_country iso_region municipality gps_code iata_code  \\\n",
       "4393       NaN          US      US-MD      Oakland     3MD2       NaN   \n",
       "\n",
       "     local_code                            coordinates  \n",
       "4393       3MD2  -79.40119934082031, 39.41320037841797  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data sample\n",
    "df_ports.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3797009</th>\n",
       "      <td>1856-07-01</td>\n",
       "      <td>21.632</td>\n",
       "      <td>1.302</td>\n",
       "      <td>Khoy</td>\n",
       "      <td>Iran</td>\n",
       "      <td>37.78N</td>\n",
       "      <td>44.75E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dt  AverageTemperature  AverageTemperatureUncertainty  City  \\\n",
       "3797009  1856-07-01              21.632                          1.302  Khoy   \n",
       "\n",
       "        Country Latitude Longitude  \n",
       "3797009    Iran   37.78N    44.75E  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data sample\n",
    "temp_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting any null values\n",
    "temp_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4352253</th>\n",
       "      <td>1797-08-01</td>\n",
       "      <td>30.145</td>\n",
       "      <td>2.104</td>\n",
       "      <td>Loni</td>\n",
       "      <td>India</td>\n",
       "      <td>28.13N</td>\n",
       "      <td>77.27E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dt  AverageTemperature  AverageTemperatureUncertainty  City  \\\n",
       "4352253  1797-08-01              30.145                          2.104  Loni   \n",
       "\n",
       "        Country Latitude Longitude  \n",
       "4352253   India   28.13N    77.27E  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data sample\n",
    "temp_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#dataframe's information\n",
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2163396</td>\n",
       "      <td>4348794.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>X96</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VQ</td>\n",
       "      <td>20665.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>SAJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VES</td>\n",
       "      <td>9.435467e+10</td>\n",
       "      <td>MANAD</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>147477</td>\n",
       "      <td>275285.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>AGA</td>\n",
       "      <td>20546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GU</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>06302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>5.546549e+10</td>\n",
       "      <td>00608</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "271     2163396  4348794.0  2016.0     4.0   525.0   525.0     X96  20567.0   \n",
       "737      147477   275285.0  2016.0     4.0   209.0   209.0     AGA  20546.0   \n",
       "\n",
       "     i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost  \\\n",
       "271      2.0      VQ  20665.0    48.0      2.0    1.0  20160423      SAJ   \n",
       "737      1.0      GU  20548.0    38.0      2.0    1.0  20160402      NaN   \n",
       "\n",
       "    occup entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum  \\\n",
       "271   NaN       G       I      NaN       M   1968.0  10222016      F     NaN   \n",
       "737   NaN       G       O      NaN       M   1978.0  06302016      M     NaN   \n",
       "\n",
       "    airline        admnum  fltno visatype  \n",
       "271     VES  9.435467e+10  MANAD       B2  \n",
       "737      DL  5.546549e+10  00608       WT  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data sample\n",
    "migration.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Defining the Data Model\n",
    "### 3.1 Conceptual Data Model\n",
    "\n",
    "#### Spending only a few minutes looking at the dataframes\n",
    "#### we have above it is pretty much a give on where\n",
    "#### we weill be getting our data for the fact table vs our dimension tables.\n",
    "\n",
    "#### again we will be using a star schema fact vs dimension tables design\n",
    "\n",
    "### With 5 tables in mind : \n",
    "#### 1) a fact table - tempratures >> From the spark_migration dataframe<< note that\n",
    "#### 2) a dimension table - demographics >> From the spark_migration dataframe\n",
    "#### 3) a dimension table - ports >> From the spark_migration dataframe\n",
    "#### 4) a dimension table - migrants >> From the spark_migration dataframe \n",
    "\n",
    "\n",
    "\n",
    "### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "#### Using spark we will perform the tasks above, a few extra steps of wrangling may be included\n",
    "#### Replacing the country codes by their names and possiply the travel modes while keeping the \n",
    "#### original data, which would allow for easier aggregation, grouping and possibly calssifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#now lets begin our spark session,\n",
    "spark= SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "#locate and read our immigration data files,\n",
    "#loading the data into a spark dataframe\n",
    "spark_migration= spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#lets load the previously wrangled data files\n",
    "spark_port= spark.read.option(\"header\",True).csv('airport-codes_csv.csv')\n",
    "spark_temp= spark.read.option(\"header\",True).csv(fname)\n",
    "spark_demo= spark.read.option(\"header\",True).csv('us-cities-demographics.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Now that we have our main data loaded in spark, lets go ahead load the rest of the data from the files we created, perform the pervious wrangling steps and proceed to creating our data lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#dropping unwanted data\n",
    "spark_migration= spark_migration.drop('Unnamed: 0','occup',\n",
    "                                       'entdepu','entdepu','insnum','biryear',\n",
    "                                       'i94yr','i94mon','count')\n",
    "#dropping al null values\n",
    "spark_migration= spark_migration.na.drop()\n",
    "\n",
    "#renaming the columns for an easier query and presentaion\n",
    "spark_migration= spark_migration.withColumnRenamed('i94cit','from_country')\n",
    "spark_migration= spark_migration.withColumnRenamed('i94res','from_residence')\n",
    "spark_migration= spark_migration.withColumnRenamed('i94visa','visa_type')\n",
    "spark_migration= spark_migration.withColumnRenamed('i94port','port_code')\n",
    "spark_migration= spark_migration.withColumnRenamed('visapost','port_city')\n",
    "spark_migration= spark_migration.withColumnRenamed('i94mode','travel_mode')\n",
    "spark_migration= spark_migration.withColumnRenamed('i94addr','state')\n",
    "spark_migration= spark_migration.withColumnRenamed('i94bir','age')\n",
    "spark_migration= spark_migration.withColumnRenamed('dtadfile','date_added')\n",
    "spark_migration= spark_migration.withColumnRenamed('entdepa','arrival_flag')\n",
    "spark_migration= spark_migration.withColumnRenamed('entdepd','departure_flag')\n",
    "spark_migration= spark_migration.withColumnRenamed('matflag','match_flag')\n",
    "spark_migration= spark_migration.withColumnRenamed('dtaddto','expiry_date')\n",
    "spark_migration= spark_migration.withColumnRenamed('admnum','admission_number')\n",
    "spark_migration= spark_migration.withColumnRenamed('fltno','flight_number')\n",
    "\n",
    "\n",
    "#dropping unwanted columns in the airports data\n",
    "spark_port = spark_port.drop('continent','iata_code','local_code','elevation_ft',\n",
    "                      'gps_code','municipality')\n",
    "\n",
    "#filtering data for the united states only\n",
    "spark_port = spark_port.filter(spark_port['iso_country']== 'US')\n",
    "\n",
    "#dropping all null values\n",
    "spark_port = spark_port.na.drop()\n",
    "\n",
    "#load the data into a pandas dataframe\n",
    "spark_port= spark_port.toPandas()\n",
    "\n",
    "#extract only thr state code from the region column\n",
    "spark_port['iso_region']= spark_port['iso_region'].str.replace(r'US-','')\n",
    "\n",
    "spark_port = spark.createDataFrame(spark_port)\n",
    "\n",
    "\n",
    "#dropping all null value in our demographics data\n",
    "spark_demo = spark_demo.na.drop()\n",
    "\n",
    "#renaming the columns for an easier query and presentaion\n",
    "spark_demo= spark_demo.withColumnRenamed('Male Population','male_population')\n",
    "spark_demo= spark_demo.withColumnRenamed('Female Population','female_population')\n",
    "spark_demo= spark_demo.withColumnRenamed('Total Population','total_population')\n",
    "spark_demo= spark_demo.withColumnRenamed('Number of Veterans','number_of_vets')\n",
    "spark_demo= spark_demo.withColumnRenamed('Foreign-born','foreign_born')\n",
    "spark_demo= spark_demo.withColumnRenamed('Average Household Size','avrg_household_size')\n",
    "spark_demo= spark_demo.withColumnRenamed('Race','race')\n",
    "spark_demo= spark_demo.withColumnRenamed('State Code','state_code')\n",
    "spark_demo= spark_demo.withColumnRenamed('Count','count_no')\n",
    "\n",
    "\n",
    "\n",
    "#filtering temprature data for the united states only\n",
    "spark_temp = spark_temp.filter(spark_temp['country']== 'United States')\n",
    "\n",
    "#renaming the columns for an easier query and presentaion\n",
    "spark_temp= spark_temp.withColumnRenamed('AverageTemperature','avg_temp')\n",
    "spark_temp= spark_temp.withColumnRenamed('AverageTemperatureUncertainty','avg_temp_uncertainty')\n",
    "\n",
    "\n",
    "#dropping all null value in our temprature data\n",
    "spark_temp = spark_temp.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#now we fit our data in a temp view to query and creae our finals tables\n",
    "spark_migration.createOrReplaceTempView('migrations')\n",
    "spark_temp.createOrReplaceTempView('temps')\n",
    "spark_demo.createOrReplaceTempView('demos')\n",
    "spark_port.createOrReplaceTempView('ports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# queries to select our wanted data tables from the loaded datarames above\n",
    "# all of the the dates in arrdat are the total days since the first reading on jan 1st,1960\n",
    "# first commercial trip year\n",
    "immigration = spark.sql(\"\"\"\n",
    "                        SELECT DISTINCT\n",
    "                          cicid,\n",
    "                          date_add(to_date('1960-01-01'), arrdate) AS date,\n",
    "                          state,\n",
    "                          admission_number,\n",
    "                          age,\n",
    "                          gender,\n",
    "                          visatype AS visa_type,\n",
    "                          flight_number\n",
    "                        FROM migrations\n",
    "                        \"\"\"\n",
    "                           )\n",
    "\n",
    "#fits the dataframe to a tempview\n",
    "immigration.createOrReplaceTempView(\"immigrations\")\n",
    "\n",
    "\n",
    "# queries to select our wanted data tables from the loaded datarames above\n",
    "airports = spark.sql(\"\"\"SELECT DISTINCT\n",
    "                         ident,\n",
    "                         type,\n",
    "                         name,\n",
    "                         iso_country,\n",
    "                         iso_region AS state,\n",
    "                         coordinates\n",
    "                         FROM ports \n",
    "                        \"\"\"\n",
    "                    )\n",
    "\n",
    "#fits the dataframe to a tempview\n",
    "airports.createOrReplaceTempView(\"airports_table\")\n",
    "\n",
    "# queries to select our wanted data tables from the loaded datarames above\n",
    "demographics = spark.sql(\"\"\"SELECT DISTINCT\n",
    "                             count_no,\n",
    "                             City,\n",
    "                             State,\n",
    "                             state_code,\n",
    "                             male_population,\n",
    "                             female_population,\n",
    "                             total_population,\n",
    "                             number_of_vets,\n",
    "                             avrg_household_size,\n",
    "                             race                            \n",
    "                            FROM demos \n",
    "                            \"\"\"\n",
    "                        )\n",
    "\n",
    "#fits the dataframe to a tempview\n",
    "demographics.createOrReplaceTempView(\"demographics\")\n",
    "\n",
    "# extrat the city to state data from our demogrphics\n",
    "city_state = spark.sql(\"\"\"SELECT DISTINCT\n",
    "                           city,\n",
    "                           state_code AS state\n",
    "                           FROM demographics\n",
    "                          \"\"\"\n",
    "                      )\n",
    "#fits the dataframe to a tempview\n",
    "city_state.createOrReplaceTempView(\"city_state\")\n",
    "\n",
    "\n",
    "# extracting, day, month and year from the dt column for our temprature data\n",
    "temp_time = spark_temp.select('dt').withColumn('month', month(spark_temp['dt']))\\\n",
    "                                    .withColumn('year', year(spark_temp['dt']))\n",
    "\n",
    "#drop duplicates if they were created here\n",
    "temp_time = temp_time.dropDuplicates(subset=['dt'])\n",
    "\n",
    "#fits the dataframe to a tempview\n",
    "temp_time.createOrReplaceTempView(\"temp_time\")\n",
    "\n",
    "#drop null values if any\n",
    "temp_time = temp_time.na.drop()\n",
    "\n",
    "\n",
    "#fits the dataframe to a tempview\n",
    "temp_time.createOrReplaceTempView(\"temp_time\")\n",
    "\n",
    "# queries to select our wanted data tables from the loaded datarames above\n",
    "# we will incliude a 15 year gap before airtravel going mainstream for comparisons.\n",
    "temperatures1 = spark.sql(\"\"\"SELECT DISTINCT\n",
    "                                temp_time.dt,\n",
    "                                temp_time.month,\n",
    "                                temp_time.year,\n",
    "                                temps.City,\n",
    "                                temps.avg_temp,\n",
    "                                temps.Latitude,\n",
    "                                temps.Longitude                              \n",
    "                            FROM temps \n",
    "                            JOIN temp_time\n",
    "                            ON temps.dt = temp_time.dt\n",
    "                            WHERE year > 1945\n",
    "                            \"\"\"\n",
    "                        )\n",
    "\n",
    "#fits the dataframe to a tempview\n",
    "temperatures1.createOrReplaceTempView(\"temperatures_table\")\n",
    "\n",
    "#drop null values if any\n",
    "temperatures1= temperatures1.na.drop()\n",
    "\n",
    "\n",
    "#Add the state code here to fascilitate easier joins and aggregations\n",
    "# for users\n",
    "temperatures = spark.sql(\"\"\"SELECT DISTINCT\n",
    "                                temperatures_table.month,\n",
    "                                temperatures_table.year,\n",
    "                                temperatures_table.City,\n",
    "                                city_state.state,\n",
    "                                temperatures_table.avg_temp,\n",
    "                                temperatures_table.Latitude,\n",
    "                                temperatures_table.Longitude                              \n",
    "                            FROM temperatures_table\n",
    "                            JOIN city_state\n",
    "                            ON temperatures_table.City = city_state.City\n",
    "                            \"\"\"\n",
    "                        )\n",
    "temperatures.createOrReplaceTempView(\"temperatures\")\n",
    "#double joins is possible but wii reduce query speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2 Data Quality Checks\n",
    "#### We will try to run some the queries that might be used by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### The immigration table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+----------------+----+------+---------+-------------+\n",
      "|   cicid|      date|state|admission_number| age|gender|visa_type|flight_number|\n",
      "+--------+----------+-----+----------------+----+------+---------+-------------+\n",
      "|274085.0|2016-04-02|   VA|  9.255303493E10|46.0|     M|       B1|        00002|\n",
      "|432764.0|2016-04-02|   VA|  9.256290193E10|63.0|     F|       B2|        00100|\n",
      "|502407.0|2016-04-03|   VA|  9.267630183E10|59.0|     F|       B2|        00087|\n",
      "|716107.0|2016-04-04|   VA|  9.275570343E10|59.0|     F|       B2|        00956|\n",
      "|835065.0|2016-04-05|   VA|  9.283845283E10|61.0|     M|       B2|        00007|\n",
      "+--------+----------+-----+----------------+----+------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test put a random yet a common type of query on this data.\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM immigrations\n",
    "    WHERE state = 'VA' AND age > 45\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- admission_number: double (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- flight_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the final schema\n",
    "immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " cicid            | 2156.0         \n",
      " date             | 2016-04-01     \n",
      " state            | CA             \n",
      " admission_number | 9.250802923E10 \n",
      " age              | 36.0           \n",
      " gender           | M              \n",
      " visa_type        | B2             \n",
      " flight_number    | 00077          \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the first row\n",
    "immigration.show(n=1, vertical= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### The main fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+-----+--------+--------+---------+\n",
      "|month|year|     City|state|avg_temp|Latitude|Longitude|\n",
      "+-----+----+---------+-----+--------+--------+---------+\n",
      "|    8|2013|Arlington|   VA|  30.255|  32.95N|   96.70W|\n",
      "|    6|2013|Arlington|   VA|  27.691|  32.95N|   96.70W|\n",
      "|    7|2013|Arlington|   VA|   28.49|  32.95N|   96.70W|\n",
      "|    9|2013|Arlington|   VA|  27.986|  32.95N|   96.70W|\n",
      "|    6|2012|Arlington|   VA|  28.142|  32.95N|   96.70W|\n",
      "+-----+----+---------+-----+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test a random yet a common type of query on this data.\n",
    "spark.sql(\"\"\"\n",
    "            SELECT \n",
    "                *\n",
    "            FROM temperatures\n",
    "            WHERE state = 'VA' AND City = 'Arlington' AND avg_temp >26\n",
    "            ORDER BY year DESC\n",
    "            \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- avg_temp: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the final schema\n",
    "temperatures.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------\n",
      " month     | 3       \n",
      " year      | 1955    \n",
      " City      | Detroit \n",
      " state     | MI      \n",
      " avg_temp  | 1.236   \n",
      " Latitude  | 42.59N  \n",
      " Longitude | 82.91W  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the first row\n",
    "temperatures.show(n=1, vertical= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The airports table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+\n",
      "|                name|state|         type|\n",
      "+--------------------+-----+-------------+\n",
      "|      Merkle Airport|   NY|small_airport|\n",
      "|UVMHN-Elizabethto...|   NY|     heliport|\n",
      "|Middlesex Valley ...|   NY|small_airport|\n",
      "|     Skyview Airport|   NY|small_airport|\n",
      "|H & H Aviation Se...|   NY|     heliport|\n",
      "+--------------------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test a random yet a common type of query on this data\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        name,\n",
    "        state,\n",
    "        type\n",
    "    FROM airports_table\n",
    "    WHERE state = 'NY'\n",
    "    ORDER BY type DESC\n",
    "    \"\"\"\n",
    "         ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the final schema\n",
    "airports.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------\n",
      " ident       | 0AL7                 \n",
      " type        | heliport             \n",
      " name        | Gadsden Regl Medi... \n",
      " iso_country | US                   \n",
      " state       | AL                   \n",
      " coordinates | -85.9653015136718... \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the first row\n",
    "airports.show(n=1, vertical= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### the demographics table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- count_no: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- number_of_vets: string (nullable = true)\n",
      " |-- avrg_household_size: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the final schema\n",
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------\n",
      " count_no            | 124108               \n",
      " City                | Greensboro           \n",
      " State               | North Carolina       \n",
      " state_code          | NC                   \n",
      " male_population     | 132251               \n",
      " female_population   | 153093               \n",
      " total_population    | 285344               \n",
      " number_of_vets      | 14011                \n",
      " avrg_household_size | 2.36                 \n",
      " race                | Black or African-... \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the first row\n",
    "demographics.show(n=1, vertical= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 rows)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test a random yet a common type of query on this data\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM demographics\n",
    "    WHERE City IS NULL\n",
    "    \"\"\"\n",
    "         ).show(vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### As expected we got no result of rentries where is the city is null\n",
    "#### also here i kept most of the as string to keep each entry's uniqness\n",
    "#### casting as int or floats and, ML users can now both use this data with min-wrangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# saving the new data lake locally as .sas files\n",
    "immigration.write.parquet('data_lake/us_immigration.sas')\n",
    "temperatures.write.parquet('data_lake/us_city_temperatures.sas')\n",
    "airports.write.parquet('data_lake/us_airports.sas')\n",
    "demographics.write.parquet('data_lake/us_city_demographics.sas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 5: Complete Project Write Up\n",
    "\n",
    "#### 1) for the clear size of our data, we have mainly deployed Pyspark to shape and process our data model and used pandas to understand the shape and get a feeling to the data in a broader way,\n",
    "\n",
    "#### 2) In the case of a constant stream of data from each source, Applying similar functions and technology, we can move this to airflow and schedule it of a daily or even an hourly basis depending on the decesions taken supported by the analysis used buy this datalake\n",
    "\n",
    "#### 3)under the following scenarios:\n",
    "\n",
    "#### -The data was increased by 100x:\n",
    "\n",
    "#### instantly move the spark session to an EMR or AWS, using AWS S3 for its cost effectivenes.\n",
    "\n",
    "#### -The data populates a dashboard that must be updated on a daily basis by 7am every day:\n",
    "\n",
    "#### In this case we would move the storage back to hadoop and maintain an active EMR cluster, using apache airflow to process the ELT on a daily basis at 7 am.\n",
    "\n",
    "#### -The database needed to be accessed by 100+ people:\n",
    "\n",
    "#### With a deployed EMR cluster on AWS, depending on the tools used by the user, using an ssh key and a few other steps dependinng on which software used, like power BI and tablue, which both are suported BY AWS and they include AWS integration prefrences as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Dict.\n",
    "\n",
    "#### The Immigration table\n",
    "##### cicid >> unique number given to each arrival       \n",
    "##### date  >> arrival date\n",
    "##### state >> arrival state        \n",
    "##### admission_number >> number given to traveller by customs\n",
    "##### age  >>  traveler's age      \n",
    "##### gender >> traveler's gender         \n",
    "##### visa_type >> tyoe of visa given to taveller\n",
    "##### flight_number >> flight number the traveller was on.       \n",
    "\n",
    "#### The Temperature table\n",
    "##### month >> month at the time of calulating the average temperatures   \n",
    "##### year >> year at the time of calulating the average temperatures\n",
    "##### City >> city measuerment was taken in \n",
    "##### state >> state measuerment was taken in      \n",
    "##### avg_temp >> average temperature calculated\n",
    "##### Latitude >> gps and map location of the data capture\n",
    "##### ngitude >> gps and map location of the data capture\n",
    "\n",
    "#### The Airports table \n",
    "##### ident >> airport id serial number          \n",
    "##### type  >> the type of port, heliports, frieght,...etc         \n",
    "##### name >> the airport's name\n",
    "##### state  >> state the airport is in              \n",
    "##### coordinates >> map coordinations of the airport\n",
    "\n",
    "#### The demographics table\n",
    "##### count_no  >> the number of the count processes since the first time at a given city          \n",
    "##### City >> city of the  population count       \n",
    "##### State  >> the state the city is in\n",
    "##### state_code  >>  the state two letter code like VA, TX, PA ..etc     \n",
    "##### male_population  >> female population of the city          \n",
    "##### female_population >>  male population of the city        \n",
    "##### total_population  >> total population of the city           \n",
    "##### number_of_vets >> average number of verts in the city             \n",
    "##### avrg_household_size  >> the average household size in the city          \n",
    "##### race >> the majority race of the city\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "I94 Immigration Data:\n",
    "https://travel.trade.gov/research/reports/i94/historical/2016.html\n",
    "\n",
    "World Temperature Data:\n",
    "https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data\n",
    "\n",
    "U.S. City Demographic Data:\n",
    "https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "\n",
    "Airport Code Table:\n",
    "https://datahub.io/core/airport-codes#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### refrences:\n",
    "https://www.marsja.se/how-to-read-sas-files-in-python-with-pandas/\n",
    "\n",
    "https://stackoverflow.com/questions/49188960/how-to-show-all-columns-names-on-a-large-pandas-dataframe\n",
    "\n",
    "https://towardsdatascience.com/data-wrangling-with-pyspark-for-beginners-3f2197c81511\n",
    "\n",
    "https://stackoverflow.com/questions/43976237/pyspark-replacing-value-in-a-column-by-searching-a-dictionary\n",
    "\n",
    "https://sparkbyexamples.com/pyspark/pyspark-cast-column-type/\n",
    "\n",
    "https://stackoverflow.com/questions/39067505/pyspark-display-a-spark-data-frame-in-a-table-format\n",
    "\n",
    "https://stackoverflow.com/questions/50523950/improve-pyspark-dataframe-show-output-to-fit-jupyter-notebook\n",
    "\n",
    "https://stackoverflow.com/questions/37038014/pyspark-replace-strings-in-spark-dataframe-column\n",
    "\n",
    "https://stackoverflow.com/questions/66311283/replacing-column-values-in-pyspark-by-iterating-through-list\n",
    "\n",
    "https://stackoverflow.com/questions/52598366/pyspark-replace-all-values-in-dataframe-with-another-values\n",
    "\n",
    "https://sparkbyexamples.com/spark/spark-functions-adding-days-months-year/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
